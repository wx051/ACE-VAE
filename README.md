# ACE-VAE: Variational Autoencoder with Attention and Context Encoding for Low-illumination Image Enhancement

# Abstract
The low-illumination image enhancement is a challenging task because color restoration, denoising, and light enhancement should all be taken into accounts. However, most previous works focus on light enhancement, which is difficult to generate high quality enhanced images. To address this dilemma, a novel deep probabilistic framework that integrates both attention mechanism and context encoding into a unique variational autoencoder (ACE-VAE) is proposed. The key components of the ACE-VAE contain a Skip Refinement Module (SRM) and a Context Encoding Module (CEM). The SRM is implemented via weighting the skip information, which adaptively extracts crucial features and filters noise features. The CEM consists of an Attention Feature Pyramid (AFP) and a Global Context Extractor (GCE). The AFP is designed to encode effective multiscale features and pay different attention to local regions. The GCE is used to capture the global contextual information. Besides, a polynomial loss that includes the content generation, denoising, and basic VAE losses is introduced to achieve a better trade-off between proper saturation and enhancement. The experiments show that the proposed model achieves better performance than the other state-of-the-art models.


# Download
[Synthetic dataset](https://pan.baidu.com/s/1upUgKuEVZInnamrKINi8Ug)(Baidu Drive password:z7fc )  
Codes(Coming soon)



